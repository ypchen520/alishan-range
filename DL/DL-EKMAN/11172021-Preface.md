# Preface

* tasks that traditionally have been performed well only by humans
  * image classification
  * general language descriptions of images (image-captioning)
  * natural language translation
  * speech-to-text and text-to-speech conversion

## What is Deep Learning

* a class of machine learning algorithms that
  * use multiple layers of computational units where
    * each layer learns its own representation of the input data
      * These layers are combined by later layers in a hierarchical fashion
* AI
  * ML
    * DL
      * DNN

## Brief History of Deep Neural Networks

### First Wave

* the first model of an artificial neuron was introduced in 1943 (McCulloch and Pitts)
* 1957: Rosenblatt perceptron
* first AI winter: a book by Minsky and Papert (1969)
  * Olazaran (1996): misrepresented?
  * Schmidhuber (2015): learning algorithm for multilevel networks (Ivakhnenko and Lapa, 1965)

### Second Wave

* the 1980s
* popularized: the backpropagation algorithm for automatic training of multilayer networks (Rumelhart et al., 1986)
  * Linnainmaa, 1970
  * Werbos, 1981
* LeNet, 1989
  * convolutional neural network (CNN)
    * handwritten zip codes (LeCun et al., 1990)
    * built on Fukushima's Neocognitron (1980): the first published CNN
* fell out of fashion
  * the limited computational capability at the time
    * prevent the network from scaling to larger problems
  * other traditional machine learning approaches were perceived as better alternatives

### Third Wave

* came together in 2012
  * a combination of algorithmic progress
  * availability of massive datasets
  * the ability to use graphics processing units (GPUs) for general purpose computing
* popularized: AlexNet (Krizhevsky et al. 2012)
  * computer vision competition known as the ImageNet challenge
* the term deep networks: 2006
  * Graves and colleagues (2009) won competitions in handwriting recognition with a neural network
  * Ciresan and colleagues (2011) used a GPU accelerated network for image classification

### More detailed description of the history of DL: Schmidhuber's (2015) overview

## Is This Book For You?

* It is important to learn about traditional ML
* linear regression

## Is DL Dangerous

* a study of a commercially available facial recognition system (Buolamwini and Gebru, 2018)
  * skin color
  * the website of the Algorithmic Justice League
* fake pornography (Dickson, 2019)
* the risk of learning and even amplifying human biases
* the emergence of algorithmic auditing
  * researchers identify and report human biases (Raji and Buolamwini, 2019)
  * the released DL model (Mitchell et al., 2018)
  * data used to create such systems (Gebru et al., 2018)
* Thomas, 2019
  * a checklist of questions to guide DL practitioners throughout the course of a project to avoid ethical problems  

## Choosing a DL Framework

* A DL framework provides funtionality that handles much of the low-level details when implementing DL models
* Caffe
* Theano
* MXNet
* Torch
* TensorFlow
* PyTorch
* Keras
* TensorRT
* the most popular
  * TensorFlow
    * the Keras API
  * PyTorch
  * MXNet
* TensorFlow vs. PyTorch

## Prerequisites for Learning DL

### Statistics and probability theory

* variance
* standardize a random variable

### Linear Algebra

* a weighted sum of variables
* describe additions and multiplications *in a compact manner*
* vectors
* matrices
* dot products
* matrix-vector multiplications
* matrix-matrix multiplications

### Calculus

* the learning part of DL is based on
  * minimizing the value of a function known as a loss function or error function
* concepts from calculus
  * computing the derivative of a function of a single variable
  * computing partial derivatives of a function of multiple variables
  * calculating derivatives using the chain rule of calculus

### Numerical methods for constrained and unconstrained optimization

* gradient descent: an iterative method
  * finding extreme points in continuous functions

### Python programming

* NumPy (numerical Python)
* pandas (Python Data Manipulation Library)
  * manipulate multidimensional data
* plotting data with matplotlib

### Data representation

* highly optimized ML frameworks
  * input data needs to be converted into **suitable formats** that can be consumed by these frameworks
* the format of the data
  * images
    * RGB representation
  * text
    * how characters are represented by a computer
* raw input data needs to be cleaned
  * missing or duplicated data entries
  * timestamps from different time zones
  * typos originating from manual processing
  
## About the Code Examples

* DL algorithns are based on stochastic optimization techniques

## How to Read This Book

* summarize a group of related techniques once they have all been introduced

### Appendixes

* Appendix A: Chapter 3
* Appendix B: Chapter 8
* Appendix C: Chapter 13
* Appendix D: Chapter 15

### Guidance for readers who do not want to read all of this book

* Computer vision track
  * Appendix B
    * object detection
    * semantic segmentation
    * instance segmentation
  * skim Chapters 9 through 11 about 
    * recurrent neural networks (RNNs)
    * time series prediction
* Language processing track
  * skim Chapter 8
    * the description of skip connections
  * read Chapters 9 through 13
  * Appendix C
  * Chapters 14 amd 15
  * Appendix D
  * word embeddings
  * GPT and BERT

## Overview of Each Chapter and Appendix

### Chapter 1 - The Rosenblatt Perceptron

### Chapter 2

### Chapter 3

### Chapter 4

### Chapter 5

### Chapter 6

### Chapter 7

### Chapter 8

### Chapter 9

### Chapter 10

### Chapter 11

### Chapter 12

### Chapter 13

### Chapter 14

### Chapter 15 

### Chapter 16

### Chapter 17

### Chapter 18

### Appendix A

### Appendix B

### Appendix C

### Appendix D

### Appendix E

### Appendix F

### Appendix G

### Appendix H

### Appendix I

### Appendix J
